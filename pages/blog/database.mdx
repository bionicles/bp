I really wanted to use a Graph Database but could not find one I could trust

Redis Labs is compelling to the hacker in me because I like the huge toolbox of data structures, but I value trust more than features, and for numerous reasons I could not bring myself to trust Redis Labs. For example, their site has 2 different prices listed for the "pro" version we'd need and both are way expensive with weird licenses. Their site has an annoying clippy avatar with a popup chat bubble (sadly and surprisingly common). Also, I'm not sure Redis as primary DB would allow great queries to come up down the road, you have to essentially design the data around the queries, which is interesting but difficult to get right in a rapidly-changing environment. The Redis Modules which would seem critical to choose Redis Labs are licensed under a weird proprietary license which says you can't use their database in a database product. They list vague examples of "database products" but don't clarify the exact definitions of those examples. Does an app with search count as a search engine? This legal uncertainty prevents me from testing the database. If you want to use Redis Labs, you'd want to use it for the modules, but they cost $1400 and you can't test them locally with docker because of the weird license. That might not seem like a lot for some, but for me it's a lot of money for features available for free elsewhere. I was excited to use Redis Labs for a primary database but the money, the clippy, the inconsistent website, made it not possible to trust Redis Labs as the bedrock of our data system.

Neo4j was a contender but there's no autoscaling hosting option and the license is GPLv3 which I'd rather not inflict on customers. Plus, they make you sign an NDA to learn the price for Enterprise edition. I don't see how I can trust them with medical research data if they can't put their price on their site. Medium uses Neo4j and I actually find Medium to be pretty bad at querying and sorting articles. I'd rather not make my site like Medium, although it's probably more Medium than Neo4j. GPLv3 - MIT / Apache2.0 relationship is a legal headache, and if you use Neo4j Community, it's basically a toy for noobs and can't handle production workloads. There's an open source version of Neo4j Enterprise but the community is tiny and there's no infrastructure as code, just a binary, so we'd have to spend our time writing infrastructure as code instead of focused on our app

ArangoDB is sweet but also has no autoscaling option and while it can do graph operations, it doesn't have openCypher style match syntax, so basically it's the same thing as Postgres (hella verbose traversals) but AQL doesn't translate to tons of other databases. If you learn AQL, it is cool, but it only works with Arango. if you learn SQL, it does most of the same stuff, but it translates to many many databases. ArangoDB has a way to make microservices in the database cluster, called Foxx, but Foxx doesn't support async/await, which rules out a huge swath of stuff you'd want to do in microservices. Further, the docs seem a bit scattered, nested, and disorganized. It takes a bunch of clicking and guesswork to navigate these docs (Postgres docs have a similar problem) Call me crazy but I love when docs are all on one page, because then I can just CTRL-F and find stuff. Maybe I should write a docs scraper. Anyway, I really want to love ArangoDB. The community and company are awesome and have lots of great ideas. I think this is my favorite option but I have a fiduciary responsibility to choose an option that's right for the business, not for my own happiness, and startups have solid reason to choose Postgres over ArangoDB (hopefully this changes) 

TigerGraph caught my eye with a (false) google ad for a "Serverless Graph Database" but it's closed-source and requires manual management of capacity guesses and scaling, which rules it out pretty much immediately as far as Bit Pharma is concenred. If you can guess which capacity option to use, the prices jump from 0 to ridiculous and there's no autoscaling / serverless option. The free tier would be cool if they didn't shut off your database and make you manually turn it back on. I think this is more of a research project led by a researcher than a battle-tested trustworthy database, but I had a productive talk with their representative and I see great things in TigerGraphs future, for people who know how to use it. Basically, I wouldn't use this as my first option for the foundation of a startup, but for huge enterprises who can afford it for research projects this could be a serious contender for specific services and projects. Looks cool for big companies but I can't really afford to take the chance.

Cassandra and Scylla are compelling options but I'm concerned they lack the capability to model graphs without having great ability to join on arrays of ids like SQL can do. This would force me to make a bunch of network requests. These are solid options for event sourcing but Scylla doesn't support triggers which would seem critical to implement sagas and that sort of thing. JanusGraph can implement graphs on these databases and is described below. DynamoDB has the best business proposition re: serverless, but I really find it unclear how to write great queries for dynamo, and it scares me as a startup founder that I need to basically design the database correctly up front to do a great job. Startups often need to change stuff fast and in SQL I can just make new queries but in Dynamo I need to rework the structure of the data. I like this as an event store because it can do streaming to lambda functions but, then again, Postgres can do that too, and one benefit about event storing in SQL is you can theoretically join projections / current state with relevant event history and present both current state of data and a full history of changes to the data consumer. That's gonna take a bunch of round trips and application code with a column store like dynamo, scylla, or cassandra when you could just use built-in features of SQL or graph databases These type of databases are interesting and compelling for certain use cases (like scaling up event sourcing at a big company) and they have open-source autoscaling / serverless hosting options, but I'm not sure I trust a database without relationships / edges as first-class citizens for my company. To me, everything is connected, and I need a database which can handle that. 

JanusGraph is an open-source alternative to Neptune and OrientDB for Gremlin, so it's potentially a better graph db because we can tinker with it, but there aren't great hosting autoscaling options for JanusGraph (IBM seems to have killed the project, or not, I can't even tell) so it's gonna be tons of distraction doing DBA tasks instead of marketing, selling, delivering a great experience for customers.  Cypher for Gremlin is cool idea but seems dead, you can't actually get a Docker image to run Cypher for Gremlin on disc, which means you'd have to install a bunch of Java stuff in a new dockerfile and juggle various docs to figure all that out. The community is open but not huge with tons of momentum like Postgres. If a few more companies pick this up and develop the devops deployment more, and add JSON to Tinkerpop, it could be huge down the road. JanusGraph is exciting, but I don't think JanusGraph can be trusted as the bedrock of a startup.

AWS Neptune is interesting but I disagree with their marketing and positioning. They write everywhere, "AWS Neptune is fully managed" but then the user must manually scale the capacity of the database. Trust really matters for me and when I see marketing hype that sounds like it isn't even technically true, I get really turned off to a database. If Neptune had Autoscaling or Serverless, I probably already would have signed up, but one concern I have with Gremlin APIs is they don't have great support for JSON, which is a critical aspect of API development. If my database can't store and query JSON and I'm writing apps in 2020 I'm pretty screwed. Also, the source code for Neptune is closed. I can't contribute fixes even if I wanted to. That's a huge problem for the momentum and velocity and security of software. Especially in software, there is exponentially more intelligence and capability outside your project team than within. My personal opinion is closed source software is usually lower quality than open source software because there are far fewer eyeballs on the code and improvements basically require a game of telephone with overworked engineers. Why trust critical data to black box systems? Just look at Windows vs Linux. I have had plenty of horrible days trying to develop on Windows, to the point I swore I'd never develop on Windows ever again. Why would I set myself up for the same problem with a database? Several databases on this list have this problem. Amazon talks a big game about how customers matter more than competitors, but their actions indicate they do fear competition. Why else would they keep their code secret? Closed-source prevents customers from improving the software they use. That's hypocritical for a company which claims to support self-service. I've already been burned on this exact problem at AWS. Their security service Cognito has serious problems for years and you cannot submit a pull request. No bueno... Next.

OrientDB is compelling as a multimodal database with open standard query languages like SQL and Gremlin etc, but it's unclear how to get autoscaling and also unclear pricing, unclear what features are reserved for "enterprise edition," and my naive impression of the database industry is Java is inferior to C for databases (neo4j + janusgraph + cassandra have this "problem" too -- maybe it's just my wrong perception) 

CosmosDB is another option with Gremlin graph API, so it shares the same pros and cons as the rest: unclear support for JSON and queries which are potentially more powerful and fast than Cypher at the cost of being much more complicated to write, read, and maintain. One huge advantage of CosmosDB is the Autopilot preview; this is actually the only "real graph database" with autoscaling on-demand pricing, which I find funny and sad. I also like the way you could use several different data models with CosmosDB. The community perceptions of CosmosDB are it's a bit slow, and my personal opinion of Microsoft closed-source software from an engineering perspective is negative after being burned a few times. I like the idea of an autoscaling gremlin database but I'm not sure I trust Microsoft to provide it.

FaunaDB is neat with serverless but super new and it has this proprietary query language FQL, just like ArangoDB has AQL and TigerGraph has GSQL. Basically, If you use FaunaDB, you have to use super new GraphQL API with questionable feature coverage, or you have to use FQL, which is a query language that only works for Fauna. Gotta switch DBs for any reason? You have to learn a new query language and your query code only works with that 1 database. 

DGraph sounds cool but there's no autoscaling hosting option and you have to use GraphQL+- which is yet another proprietary query language. If I have to manage the hosting, capacity, monitoring, scaling, and learn a new language, when do I have time to work on the business? I don't want to work on your database. I want your database to help me work on my business.

MemGraph might be compelling because it apparently supports Cypher (I love Cypher) has no autoscaling option. You go to sign up and the first thing you need to do is choose some arbitrary capacity level. As if I know how many resources your database needs? This basically killed my interest in the project. Next! 

AnzoGraph license is weird. They say on their site it's free for commercial use, but the fine print of the license says, "you have no rights except what we grant in this document" --- then it lists tons of restrictions for waht you can't do with the software and I can't find any rights actually granted in the document! Seems like a bit of a license troll scam, IDK, All this so I can manage the hosting, scaling, monitoring? Next. 

GunJS is super cool but I worry it's too new and maintained by a smaller team who wants to do a ton of stuff (potentially more than they could possibly handle), and there's not a great query language, it's a Key Value store with circular references. If this had more Gremlin-style steps like filter or search or pattern matching API then it would be a much stronger contender in my book because GunJS is a valuable idea. Alas, I can't take a risk on customers' data.

Cayley is Apache 2.0 graph DB written in Golang, and can use scalable storage engines which could autoscale, but one concern here is the need again to manage the server capacity and monitoring to run the database, I'm not sure how fast the community moves and I'm not sure which of 3 query languages is the one to use. I would probably use Gremlin but I don't think it support 

MongoDB is convenient for JS app development, has lots of hosting options, and can do pretty much everything I want to do, including schema validation, field-level redactions for privacy and security, but I can't trust Mongo for a few reasons. 1 is, the license is not permissive (they changed their license like Redis) 2. their autoscaling option only starts at higher capacity levels, which seems silly because usage volatility is inversely proportional to capacity (that's physics 101, F=MA, smaller databases by have more need for autoscaling because it takes less excess capacity to overload them) 3. the query language is proprietary, meaning it's only gonna work on MongoDB and not anywhere else. I love the $populate and $graphLookup operators, and MongoDB is admittedly super cool and compelling. However, if you look at the community's perception of MongoDB on various blogs and sites like Hacker News, then you find a ton of people seem to think this is a database for noobs, that "cofounders don't let cofounders use MongoDB" .. a lot of their crowing seems unfounded right now because MongoDB has fixed the issues they complained about (for example, people say you shouldn't use Mongo because it has no schema validation, but it does, and they say you can't do joins / graph traversals, but it can, and they say it's insecure, but it can be...) I hate to be the guy who just rides the wave of public opinion, but business, especially health business, is about TRUST (thanks for teaching me that, Mike) and if engineers think our database is for noobs, then they'll think we are noobs, and who trusts a noob with data?

MySQL is interesting but I take issue with the GPL license because it gives me legal headaches. I think a lot of open source projects choose GPL for ideological reasons surrounding the collectivist philosophy of the hacker intelligensia, but the GPL license to me, is focused on helping hobbyists retain the right to tinker with their projects. MIT licensed projects like Bit Pharma still allow tinkerers, but they also allow businesses to take the project in closed-source directions. For GPL proponents, that is a feature (you have to open source your changes) but for me, it's a relic of an era where hackers were hobbyists. Nowadays, hackers are entrepreneurs, and code is a career, not a hobby. If you force your customers to use a certain license, you restrict their freedom. One might argue the end user of databases is the developer, not the app user, and GPL license restricts developer freedom to sell proprietary code. That's why I support MIT, BSD, and Apache 2.0 licenses, rather than GPL licenses... this viral mechanism is not necessary, and it limits economic freedom for developers. If someone can make a better version of my stuff, and customers choose that version, that's the free market at work. I'd rather focus on customers than legal BS. GPL works for Linux because it's a system library, but I think MIT is the right license for business because it's simple and clear. Apache 2.0 might be better in some ways, but that's a discussion for another time

Oracle has an open source language PGQL like cypher but I'm not clear how to get started. Their website is confusing and it just seems really enterprisey and confusing and potentially expensive. I dont think any other databases support PGQL besides oracle and the documentation is pretty barren about how you'd get started writing an API with PGQL and Oracle. I like that it's potentially autoscaling but I'm pretty sure the "Autonomous Database" is closed-source and I just don't want to get sucked into that type of solution.

Postgres uses SQL, which comes with many ups and downs.  I'm sorry to say I resisted this database for too long. Part of that is because I'm a huge proponent of Graph Databases. Maybe I drank the Neo4j kool-aid about how bad joins are, but I think openCypher is a joy to write, read, and maintain, and I would love to use it instead of SQL if there were an option to do so. AgensGraph allegedly lets you run openCypher on Postgres but there's only a java driver and I use Nodejs, and the docs for AgensGraph are not stellar. I also think the docs for Postgres need work re: more examples and making it easier to find stuff, but the Postgres docs are at least way more complete than many other databases. One huge downside of Postgres is it depends heavily on a carefully written DDL Schema, but there is no tool built in to Postgres that lets you manage the schema in a declarative way. It's amazing there's this huge community of Postgres users and everyone uses some weird janky script or ORM middleware to handle such a critical task as deployment of the database schema. This seems like something which should be built into the database instead of re-built in a half-ass way by thousands of independent developers. Anyway, that's the number one think I dislike about postgres, the schema management devops experience. Luckily there are many tools in many languages to handle this. I like sqldef because I can write a schema how I want it to be and it will figure out how to convert the declarative schema into imperative migrations. One concern with that though is these automated migration tools don't handle renaming things, which is a pretty big problem since naming things is widely known to be hard. If you write manual migration scripts you're liable to screw it up, and if you look at one script then you don't get the full picture. I think the workaround here is to use sqldef mostly, save the imperative migrations in a folder and write the others manually. Then apply the migrations with a tool like <https://github.com/thomwright/postgres-migrations#readme> --- and after the migrations are applied, dump the current schema and save that in version control. This is like event sourcing for database schemas because we record all change events to the schema but we also keep a projection of the current version of the schema so we can go directly to that and make changes and diff it. 

There are nice tools like Hasura to make Postgres APIs, manage migrations and do fine-grained access control, but one concern with Hasura is it implements fine-grained access rules in Haskell, which forces you to only ever use Hasura to connect to the database. Any security rules developed with Hasura wouldn't apply with other postgres drivers or direct connections. I think it's a better plan for mission-critical data to implement the security rules in Postgres SQL schema because then if you want to use a different API technology, you don't have to port a bunch of important security code in production. 

What I do like about Postgres is the huge open community, which means it's likely more feature-complete and battle tested than anything else on this list, and the community has lots of momentum to add even more features and there are plenty of people to ask if questions arise. Further, there are many many options to host Postgres with autoscaling and patches handled. For a small startup, not having to manage the database capacity is huge because that's basically a never ending 24/7 job which ought to be automated. Postgres has JSONB data type which works in queries (you can't do that so easily with neo4j even) and Postgres has full-text indexing and search built in. Postgres can handle fine-grained ABAC with Row Level Security policies (although one key gotcha here is these policies don't work with the materialized views)  and despite the crowing of Neo4j openCypher chauvinists, Postgres can easily model many to many graphs because you can JOIN using an array of ids. Recursive SQL could easily model breadth-first search, although I'm still learning how to limit the recursion depth. Postgres supports JSON, Search, and Graph features you'd pay $1400 a month for from Redis Labs, and it does that for free.  SQL isn't sexy but it's an open standard and portable skill widely used. 

TLDR: I spent tons of time, work, and struggle evaluating databases for my medical research startup because I'm passionate about graphs and wanted to use a graph database like Neo4j but I wound up just picking postgres because it has an open/permissive license, can model graphs, can do fine-grained security, has a huge community, has lots of autoscaling hosting options, is well-respected by the community  
